import base64
import os

import pandas as pd
import streamlit as st

# Utility functions


def load_evaluations(filename="evaluations.csv"):
    return pd.read_csv(filename)


def file_download_link(df, filename):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">Download evaluations.csv</a>'
    return href


def save_evaluation(evaluation, filename="evaluations.csv"):
    new_eval = pd.DataFrame([evaluation])
    if os.path.exists(filename):
        existing_df = pd.read_csv(filename)
        existing_df = existing_df[
            existing_df["text_pair_id"] != evaluation["text_pair_id"]
        ]
        updated_df = pd.concat([existing_df, new_eval], ignore_index=True)
    else:
        updated_df = new_eval
    updated_df.sort_values(by=["text_pair_id"], inplace=True)
    updated_df.to_csv(filename, index=False)
    st.success("Evaluation saved")
    return updated_df


def initialize_session_state(evaluations_df, text_pairs):
    if "current_index" not in st.session_state:
        st.session_state.current_index = 0
    if "evaluated_pairs" not in st.session_state:
        st.session_state.evaluated_pairs = evaluations_df["text_pair_id"].tolist()
    if "non_evaluated_pairs" not in st.session_state:
        st.session_state.non_evaluated_pairs = [
            pair["text_pair_id"]
            for pair in text_pairs
            if pair["text_pair_id"] not in st.session_state.evaluated_pairs
        ]


def update_session_state(current_pair_id):
    if current_pair_id not in st.session_state.evaluated_pairs:
        st.session_state.evaluated_pairs.append(current_pair_id)
    if current_pair_id in st.session_state.non_evaluated_pairs:
        st.session_state.non_evaluated_pairs.remove(current_pair_id)


def navigate_to(page):
    st.experimental_set_query_params(page=page)


# Main app

# Load the text pairs from the local CSV file
mode = "few"
file_name = "evaluations.csv"
if mode == "few":
    file_path = f"evalcsv/aykut/{file_name}"
elif mode == "full":
    file_path = f"evalcsv/full/{file_name}"

text_pairs = pd.read_csv(file_path)
text_pairs = text_pairs.to_dict("records")
text_pairs = sorted(text_pairs, key=lambda x: x["text_pair_id"])

# Load existing evaluations
evaluations_df = load_evaluations(file_path)

# Initialize session state
initialize_session_state(evaluations_df, text_pairs)

# Sidebar
st.sidebar.header("Text Pairs")

# Information Navigation
if st.sidebar.button("How to Evaluate?", key="info_button"):
    navigate_to("info")

st.sidebar.subheader("Evaluated Text Pairs")
for pair_id in st.session_state.evaluated_pairs:
    if st.sidebar.button(f"Text Pair {pair_id}", key=f"evaluated_{pair_id}"):
        st.session_state.current_index = pair_id - 1
        navigate_to("evaluation")
        st.rerun()

st.sidebar.subheader("Non-Evaluated Text Pairs")
for pair_id in st.session_state.non_evaluated_pairs:
    if st.sidebar.button(f"Text Pair {pair_id}", key=f"non_evaluated_{pair_id}"):
        st.session_state.current_index = pair_id - 1
        navigate_to("evaluation")
        st.rerun()

# Page Navigation
query_params = st.experimental_get_query_params()
page = query_params.get("page", ["evaluation"])[0]

if page == "info":
    st.header("Evaluation Information")
    st.info(
        """
        **Aim:** The goal of this human evaluation is to assess the quality of text simplifications generated by various models. 
        You will be presented with pairs of original and simplified texts. For each pair, you need to evaluate the simplification based on three metrics:
        
        1. **Adequacy**: How accurately the simplified text preserves the meaning of the original text.
        2. **Fluency**: How grammatically correct and natural the simplified text is.
        3. **Simplicity**: How much simpler the simplified text is compared to the original text.
        
        **Procedure:**
        1. Select a text pair from the list.
        2. Read both the original and simplified texts.
        3. Rate the simplified text on Adequacy, Fluency, and Simplicity using the provided radio buttons.
        4. Submit your evaluation.
        5. Move to the next text pair using the navigation buttons.
        """
    )
    if st.button("Back to Evaluation"):
        navigate_to("evaluation")
        st.rerun()

elif page == "evaluation":
    # Metrics
    metrics = ["adequacy", "fluency", "simplicity"]

    # Display current text pair
    current_pair = text_pairs[st.session_state.current_index]
    st.subheader(f"Text Pair {current_pair['text_pair_id']}")
    st.write(f"**Original Text:** {current_pair['original']}")
    st.write(f"**Simplified Text:** {current_pair['simplified']}")

    # Check if current pair has been evaluated
    existing_evaluation = evaluations_df[
        evaluations_df["text_pair_id"] == current_pair["text_pair_id"]
    ]
    evaluation = {
        "text_pair_id": current_pair["text_pair_id"],
        "original": current_pair["original"],
        "simplified": current_pair["simplified"],
        "model_id": current_pair["model_id"],
    }

    # Display evaluation status message
    if not existing_evaluation.empty:
        st.info(
            "This text pair has already been evaluated. If you would like to change it, please feel free to do so."
        )

    for metric in metrics:
        if not existing_evaluation.empty and pd.notna(
            existing_evaluation[metric].values[0]
        ):
            evaluation[metric] = existing_evaluation[metric].values[0]
        else:
            evaluation[metric] = 2

        options = [0, 1, 2, 3, 4]
        evaluation[metric] = st.radio(
            f"{metric} (0-4)",
            options,
            index=(
                options.index(evaluation[metric])
                if evaluation[metric] in options
                else 2
            ),
            key=f"{metric}_{current_pair['text_pair_id']}",
            horizontal=True,
        )

    # Navigation buttons
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        if (
            st.button("Previous", key="previous_button")
            and st.session_state.current_index > 0
        ):
            st.session_state.current_index -= 1
            navigate_to("evaluation")
            st.rerun()
    with col2:
        if (
            st.button("Next", key="next_button")
            and st.session_state.current_index < len(text_pairs) - 1
        ):
            st.session_state.current_index += 1
            navigate_to("evaluation")
            st.rerun()
    with col3:
        if st.button("Submit Evaluation", key="submit_button"):
            evaluations_df = save_evaluation(evaluation)
            update_session_state(current_pair["text_pair_id"])
            navigate_to("evaluation")
            st.rerun()

    # Add a download button for evaluations.csv
    st.markdown(
        file_download_link(evaluations_df, "evaluations.csv"), unsafe_allow_html=True
    )

    # Display collected evaluations for debugging purposes
    st.write("Collected Evaluations (for debugging):")
    st.write(evaluations_df)
